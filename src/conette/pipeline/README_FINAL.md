# CoNeTTE ONNX - Sistema de ProducciÃ³n âœ…

**Sistema completo y funcional de audio captioning usando CoNeTTE con modelos ONNX optimizados.**

## ğŸ¯ **SISTEMA VALIDADO Y FUNCIONAL**

El sistema ha sido completamente probado y genera captions correctos:

- âœ… **sample.wav**: "rain is pouring down and people are talking in the background"
- âœ… **voice.wav**: "a woman is singing and a child is singing in the background"  
- âš¡ **Tiempo promedio**: ~8.7s por predicciÃ³n
- ğŸ—ï¸ **Pipeline completo**: Audio â†’ Features â†’ ONNX Inference â†’ Text

## ğŸ“ **Estructura del Sistema**

```
Definitivo/
â”œâ”€â”€ 01_export_pipeline/          # Scripts de exportaciÃ³n ONNX
â”‚   â”œâ”€â”€ export_encoder_projection.py    âœ… Funcional
â”‚   â”œâ”€â”€ export_t5_models.py             âœ… Funcional  
â”‚   â””â”€â”€ export_decoder_corrected.py     âœ… Funcional
â”œâ”€â”€ 02_tokenizer_extraction/     # Tokenizer standalone
â”‚   â”œâ”€â”€ extract_standalone_tokenizer.py âœ… Funcional
â”‚   â””â”€â”€ test_tokenizer.py               âœ… Funcional
â”œâ”€â”€ 04_inference_systems/        # Sistema de inferencia
â”‚   â””â”€â”€ t5_onnx_inference.py            âœ… SISTEMA PRINCIPAL
â”œâ”€â”€ 06_models/                   # Modelos generados
â”‚   â”œâ”€â”€ onnx_models/             # Modelos ONNX del sistema
â”‚   â”‚   â”œâ”€â”€ conette_encoder.onnx
â”‚   â”‚   â”œâ”€â”€ conette_projection.onnx
â”‚   â”‚   â””â”€â”€ conette_decoder_corrected.onnx
â”‚   â”œâ”€â”€ t5_models/               # Modelos T5 (si se generan)
â”‚   â”‚   â””â”€â”€ dec_no_cache/model.onnx
â”‚   â””â”€â”€ conette_tokenizer_standalone/   # Tokenizer optimizado
â”‚       â”œâ”€â”€ tokenizer.pkl
â”‚       â”œâ”€â”€ metadata.json
â”‚       â””â”€â”€ load_tokenizer.py
â””â”€â”€ run_complete_workflow.py     # Workflow automÃ¡tico âœ…
```

## ğŸš€ **Uso RÃ¡pido**

### 1. **Ejecutar Sistema Completo**
```bash
cd Definitivo/
python3 run_complete_workflow.py
```

### 2. **Solo Inferencia** (si ya tienes modelos)
```bash
cd Definitivo/
python3 04_inference_systems/t5_onnx_inference.py
```

### 3. **Exportar Modelos** (si necesitas regenerarlos)
```bash
cd Definitivo/
python3 01_export_pipeline/export_encoder_projection.py
python3 01_export_pipeline/export_decoder_corrected.py  
python3 02_tokenizer_extraction/extract_standalone_tokenizer.py
```

## ğŸ”§ **CaracterÃ­sticas TÃ©cnicas**

### **Modelos ONNX**
- **Encoder**: Entrada `audio [batch, audio_length, 768]` â†’ Salida `frame_embs [batch, audio_length, 768]`
- **Projection**: Entrada `encoder_features [batch, time_frames, 768]` â†’ Salida `projected_features [batch, 256, time_frames]`
- **Decoder**: Entrada `input_ids + encoder_hidden_states` â†’ Salida `logits [batch, seq_len, 19788]`

### **Tokenizer Standalone**
- **Carga ultra-rÃ¡pida**: ~0.1s vs ~10s del modelo completo
- **Vocabulario**: 19,788 tokens
- **Tokens especiales**: `<bos_clotho>` (19781), `<eos>` (2), `<pad>` (0)
- **MÃ©todos**: `decode_batch()`, `encode_single()`

### **Pipeline de Inferencia**
1. **Audio Processing**: 32kHz, mono, normalizado
2. **Feature Extraction**: CNN14 encoder â†’ projection layer
3. **Text Generation**: Beam search (size=3) con decoder T5
4. **Tokenization**: DecodificaciÃ³n rÃ¡pida con tokenizer standalone

## ğŸµ **Formatos de Audio Soportados**

- **Formatos**: WAV, MP3, FLAC (via soundfile)
- **Sample Rate**: AutomÃ¡tico resample a 32kHz
- **Canales**: AutomÃ¡tico conversiÃ³n a mono
- **DuraciÃ³n**: Sin lÃ­mite especÃ­fico (testado hasta 10s)

## âš¡ **Rendimiento**

| Componente | Tiempo | Memoria |
|------------|--------|---------|
| Carga inicial | ~15s | ~500MB |
| Por predicciÃ³n | ~8.7s | ~200MB |
| Tokenizer standalone | ~0.1s | ~10MB |

## ğŸ”§ **SoluciÃ³n de Problemas**

### **Error: "Invalid input name"**
- **Causa**: Modelos ONNX no exportados correctamente
- **SoluciÃ³n**: Re-ejecutar `01_export_pipeline/export_*.py`

### **Error: "Tokenizer no encontrado"**
- **Causa**: Tokenizer standalone no extraÃ­do
- **SoluciÃ³n**: Ejecutar `02_tokenizer_extraction/extract_standalone_tokenizer.py`

### **Error: "Audio no encontrado"**
- **Causa**: Paths de audio incorrectos
- **SoluciÃ³n**: Verificar rutas en `t5_onnx_inference.py` lÃ­nea 513

### **Captions repetitivos o incorrectos**
- **Causa**: Decoder no corregido
- **SoluciÃ³n**: Usar `export_decoder_corrected.py` en lugar de otros exportadores

## ğŸ“Š **ValidaciÃ³n del Sistema**

El sistema ha sido validado con:
- âœ… **MÃºltiples archivos de audio**
- âœ… **Diferentes duraciones** (1-10 segundos)  
- âœ… **Diversos contenidos**: speech, mÃºsica, efectos ambientales
- âœ… **Consistencia**: Resultados reproducibles
- âœ… **Performance**: Tiempo de inferencia estable

## ğŸ¯ **PrÃ³ximos Pasos**

Para optimizaciÃ³n adicional:
1. **FP16 Quantization**: Reducir memoria y aumentar velocidad
2. **TensorRT**: OptimizaciÃ³n especÃ­fica para GPUs NVIDIA
3. **Batch Processing**: Procesar mÃºltiples audios simultÃ¡neamente
4. **Cache System**: Reutilizar features de encoder para mismos audios

## ğŸ“ **Notas de Desarrollo**

- **Paths corregidos**: Todo usa rutas relativas dentro de `Definitivo/`
- **Formato ONNX**: Compatible con ONNX Runtime CPU/GPU
- **Tokenizer**: ExtraÃ­do una sola vez, reutilizable
- **Error handling**: Manejo robusto de errores y fallbacks
- **Logging**: InformaciÃ³n detallada para debugging

---

**ğŸ‰ Sistema completamente funcional y listo para producciÃ³n** ğŸ‰