#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
TEST TOKENIZER STANDALONE
=========================

Prueba el tokenizer extra√≠do para verificar que funciona correctamente.
"""

import sys
import time
import logging
from pathlib import Path

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_standalone_tokenizer():
    """Probar tokenizer standalone."""
    
    logger.info("üß™ Probando tokenizer standalone...")
    
    try:
        # Importar cargador
        sys.path.append('../06_models/conette_tokenizer_standalone')
        from load_tokenizer import StandaloneTokenizerLoader
        
        # Cargar tokenizer
        start_time = time.time()
        loader = StandaloneTokenizerLoader('../06_models/conette_tokenizer_standalone')
        tokenizer, metadata = loader.load()
        load_time = time.time() - start_time
        
        logger.info(f"‚úÖ Tokenizer cargado en {load_time:.3f}s")
        logger.info(f"üìä Vocab size: {metadata['vocab_size']}")
        
        # Test encode/decode
        test_texts = [
            "a woman is singing",
            "rain is falling",
            "bicycle bell ringing",
            "children playing in background"
        ]
        
        for text in test_texts:
            # Encode
            tokens = tokenizer.encode_single(text)
            
            # Decode
            if hasattr(tokenizer, 'decode_batch'):
                decoded = tokenizer.decode_batch([tokens])[0]
            elif hasattr(tokenizer, 'decode_single'):
                decoded = tokenizer.decode_single(tokens)
            else:
                decoded = "Manual decode needed"
            
            logger.info(f"'{text}' ‚Üí {tokens[:5]}... ‚Üí '{decoded}'")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        return False

if __name__ == "__main__":
    test_standalone_tokenizer()